\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}PUNTO 3 }{1}{section.1}\protected@file@percent }
\newlabel{punto-3---alejandra-ruiz}{{1}{1}{PUNTO 3}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}LECTURA DEL ARCHIVO WINE QUALITY}{1}{subsection.1.1}\protected@file@percent }
\newlabel{lectura-del-archivo-wine-quality}{{1.1}{1}{LECTURA DEL ARCHIVO WINE QUALITY}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}ELIMINAR COLUMNAS}{2}{subsubsection.1.1.1}\protected@file@percent }
\newlabel{eliminar-columnas}{{1.1.1}{2}{ELIMINAR COLUMNAS}{subsubsection.1.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}VERIFICO QUE TODAS LAS VARIABLES TENGAN EL TIPO DE DATO CORRECTO Y QUE NO HAYAN NULOS}{2}{subsubsection.1.1.2}\protected@file@percent }
\newlabel{verifico-que-todas-las-variables-tengan-el-tipo-de-dato-correcto-y-que-no-hayan-nulos}{{1.1.2}{2}{VERIFICO QUE TODAS LAS VARIABLES TENGAN EL TIPO DE DATO CORRECTO Y QUE NO HAYAN NULOS}{subsubsection.1.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}ESTANDARIZAR}{2}{subsection.1.2}\protected@file@percent }
\newlabel{estandarizar}{{1.2}{2}{ESTANDARIZAR}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}HACEMOS USO DE LA LIBRERÍA SKLEARN}{2}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{hacemos-uso-de-la-libreruxeda-sklearn}{{1.2.1}{2}{HACEMOS USO DE LA LIBRERÍA SKLEARN}{subsubsection.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}CÁLCULO DE LAS CORRELACIONES}{3}{subsection.1.3}\protected@file@percent }
\newlabel{cuxe1lculo-de-las-correlaciones}{{1.3}{3}{CÁLCULO DE LAS CORRELACIONES}{subsection.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}PEARSON}{4}{subsubsection.1.3.1}\protected@file@percent }
\newlabel{pearson}{{1.3.1}{4}{PEARSON}{subsubsection.1.3.1}{}}
\newlabel{la-mayor-correlaciuxf3n-contra-la-variable-y-densidad-es-con-alcohol-de-manera-negativa--0.78-uxe1zucar-residual-de-manera-positiva-0.84-y-una-correlaciuxf3n-media-0.53-con-diuxf3xido-de-azuxfafre-total}{{1.3.1}{5}{La mayor correlación contra la variable Y (Densidad) Es con Alcohol de manera negativa (-0.78), Ázucar Residual de manera positiva (0.84), y una correlación media (0.53) con Dióxido de Azúfre Total}{section*.1}{}}
\@writefile{toc}{\contentsline {subparagraph}{La mayor correlación contra la variable Y (Densidad) Es con Alcohol de manera negativa (-0.78), Ázucar Residual de manera positiva (0.84), y una correlación media (0.53) con Dióxido de Azúfre Total}{5}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}KENDALL}{6}{subsubsection.1.3.2}\protected@file@percent }
\newlabel{kendall}{{1.3.2}{6}{KENDALL}{subsubsection.1.3.2}{}}
\newlabel{comparando-frente-a-pearson-la-correlaciuxf3n-fuerte-que-tenuxeda-densidad-y-uxe1zucar-residual-disminuyuxf3-0.59-significativamente-y-con-alcohol-tambiuxe9n-bajuxf3-pero-no-tanto--0.64.-incrementuxf3-de-forma-negativa-un-poco-la-correlaciuxf3n-de-uxe1cido-cuxedtrico-frente-a-todas-las-variables.}{{1.3.2}{7}{Comparando frente a Pearson, la correlación fuerte que tenía Densidad y Ázucar Residual disminuyó (0.59) significativamente, y con Alcohol también bajó pero no tanto (-0.64). Incrementó de forma negativa un poco la correlación de Ácido Cítrico frente a todas las variables}{section*.2}{}}
\@writefile{toc}{\contentsline {subparagraph}{Comparando frente a Pearson, la correlación fuerte que tenía Densidad y Ázucar Residual disminuyó (0.59) significativamente, y con Alcohol también bajó pero no tanto (-0.64). Incrementó de forma negativa un poco la correlación de Ácido Cítrico frente a todas las variables.}{7}{section*.2}\protected@file@percent }
\newlabel{recordemos-que-kendall-penaliza-por-esta-razuxf3n-es-menor-adicionalmente-pearson-es-muy-buneo-cuando-suxed-hay-comportamientos-lineales-y-al-observar-las-gruxe1ficas-de-disperciuxf3n-claramente-se-ve-un-comportamiento-eluxedptico-entre-densidad-y-alcohol-por-eso-kendall-no-bajuxf3-tanto-esta-correlaciuxf3n-pero-la-de-uxe1zucar-residual-tenuxeda-unos-puntos-atuxedpicos-alejados-de-la-concentraciuxf3n-pero-que-conservaban-linealidad-y-por-eso-es-que-kendall-suxed-bajuxf3-significativamente-esta-correlaciuxf3n-dado-que-pearson-suxed-se-afecta-bastante-con-los-atuxedpicos-kendall-no.}{{1.3.2}{7}{Recordemos que Kendall Penaliza, por esta razón es menor, adicionalmente Pearson es muy buneo cuando sí hay comportamientos lineales, y al observar las gráficas de disperción, claramente se ve un comportamiento elíptico entre Densidad y Alcohol, por eso Kendall no bajó tanto esta correlación, pero la de Ázucar Residual tenía unos puntos atípicos alejados de la concentración, pero que conservaban linealidad, y por eso es que Kendall sí bajó significativamente esta correlación, dado que Pearson sí se afecta bastante con los atípicos, Kendall NO}{section*.3}{}}
\@writefile{toc}{\contentsline {subparagraph}{Recordemos que Kendall Penaliza, por esta razón es menor, adicionalmente Pearson es muy buneo cuando sí hay comportamientos lineales, y al observar las gráficas de disperción, claramente se ve un comportamiento elíptico entre Densidad y Alcohol, por eso Kendall no bajó tanto esta correlación, pero la de Ázucar Residual tenía unos puntos atípicos alejados de la concentración, pero que conservaban linealidad, y por eso es que Kendall sí bajó significativamente esta correlación, dado que Pearson sí se afecta bastante con los atípicos, Kendall NO.}{7}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}SPEARMAN}{7}{subsubsection.1.3.3}\protected@file@percent }
\newlabel{spearman}{{1.3.3}{7}{SPEARMAN}{subsubsection.1.3.3}{}}
\newlabel{con-spearman-frente-a-pearson-bajuxf3-pero-muy-poco-la-correlaciuxf3n-entre-densidad-y-uxe1zucar-residual-pero-incrementuxf3-la-correlaciuxf3n-frente-a-las-demuxe1s-variables-incluuxedda-alcohol-exceptuando-uxe1cido-cuxedtrico.-recordemos-que-pearson-es-muxe1s-sencible-a-los-outliers-y-como-podemos-observar-en-el-diagrama-de-dispersiuxf3n-el-de-uxe1zucar-vs-densidad-hay-varios-outliars-que-aunque-estuxe1n-alineados-con-los-demuxe1s-esto-puede-estar-generando-un-incremento-en-la-correlaciuxf3n-vs-el-de-spearman.}{{1.3.3}{9}{Con Spearman frente a Pearson, bajó pero muy poco la correlación entre Densidad y Ázucar Residual, pero incrementó la correlación frente a las demás variables incluída Alcohol, exceptuando Ácido Cítrico. Recordemos que Pearson es más sencible a los Outliers, y como podemos observar en el diagrama de dispersión, el de Ázucar vs Densidad, hay varios outliars, que aunque están alineados con los demás, esto puede estar generando un incremento en la correlación vs el de Spearman}{section*.4}{}}
\@writefile{toc}{\contentsline {subparagraph}{Con Spearman frente a Pearson, bajó pero muy poco la correlación entre Densidad y Ázucar Residual, pero incrementó la correlación frente a las demás variables incluída Alcohol, exceptuando Ácido Cítrico. Recordemos que Pearson es más sencible a los Outliers, y como podemos observar en el diagrama de dispersión, el de Ázucar vs Densidad, hay varios outliars, que aunque están alineados con los demás, esto puede estar generando un incremento en la correlación vs el de Spearman.}{9}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}MODELADO}{9}{subsection.1.4}\protected@file@percent }
\newlabel{modelado}{{1.4}{9}{MODELADO}{subsection.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}PARTICIÓN DEL DATASET}{9}{subsubsection.1.4.1}\protected@file@percent }
\newlabel{particiuxf3n-del-dataset}{{1.4.1}{9}{PARTICIÓN DEL DATASET}{subsubsection.1.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Recordemos que la Matriz más invertible es la Matriz Identidad, la cuál sería que no hubiera ninguna correlación entre variables, (tener correlaciones cercanas a 0), La Calidad de una Matriz se evalúa a partir de su Capacidad de Invertibilidad, y como analizamos, la mayoría de correlaciones entre las X está más cercanas a 0, por lo que validamos este supuesto para obtener buenos valores de ˆβ}{9}{subsubsection.1.4.2}\protected@file@percent }
\newlabel{recordemos-que-la-matriz-muxe1s-invertible-es-la-matriz-identidad-la-cuuxe1l-seruxeda-que-no-hubiera-ninguna-correlaciuxf3n-entre-variables-tener-correlaciones-cercanas-a-0-la-calidad-de-una-matriz-se-evaluxfaa-a-partir-de-su-capacidad-de-invertibilidad-y-como-analizamos-la-mayoruxeda-de-correlaciones-entre-las-x-estuxe1-muxe1s-cercanas-a-0-por-lo-que-validamos-este-supuesto-para-obtener-buenos-valores-de-ux2c6ux3b2}{{1.4.2}{9}{Recordemos que la Matriz más invertible es la Matriz Identidad, la cuál sería que no hubiera ninguna correlación entre variables, (tener correlaciones cercanas a 0), La Calidad de una Matriz se evalúa a partir de su Capacidad de Invertibilidad, y como analizamos, la mayoría de correlaciones entre las X está más cercanas a 0, por lo que validamos este supuesto para obtener buenos valores de ˆβ}{subsubsection.1.4.2}{}}
\newlabel{separar-la-matriz-de-correlaciuxf3n-dejar-suxf3lo-entre-las-variables-x-y-dejar-la-de-la-variable-y-con-x-como-densidad-es-la-penuxfaltima-columna-significa-que-la-penuxfaltima-fila-tambiuxe9n-representa-la-correlaciuxf3n-de-la-x-con-y--densidad-}{{1.4.2}{9}{Separar la Matriz de Correlación, dejar sólo entre las Variables X y dejar la de la Variable Y con X (Como Densidad es la Penúltima Columna, significa que la penúltima fila también representa la correlación de la X con Y -Densidad-)}{section*.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Separar la Matriz de Correlación, dejar sólo entre las Variables X y dejar la de la Variable Y con X (Como Densidad es la Penúltima Columna, significa que la penúltima fila también representa la correlación de la X con Y -Densidad-)}{9}{section*.5}\protected@file@percent }
\newlabel{invertir-la-matriz-de-correlaciuxf3n-entre-las-variables-x}{{1.4.2}{10}{Invertir la Matriz de Correlación entre las Variables X}{section*.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Invertir la Matriz de Correlación entre las Variables X}{10}{section*.6}\protected@file@percent }
\newlabel{multipliaciuxf3n-de-matrices-para-calcular-beta}{{1.4.2}{10}{MULTIPLIACIÓN DE MATRICES PARA CALCULAR BETA}{section*.7}{}}
\@writefile{toc}{\contentsline {paragraph}{MULTIPLIACIÓN DE MATRICES PARA CALCULAR BETA}{10}{section*.7}\protected@file@percent }
\newlabel{obtener-la-media-de-x-y-y-ux2c6ux3bcy-ux2c6ux3bcx}{{1.4.2}{10}{OBTENER LA MEDIA DE X y Y (ˆμY ˆμX)}{section*.8}{}}
\@writefile{toc}{\contentsline {paragraph}{OBTENER LA MEDIA DE X y Y (ˆμY ˆμX)}{10}{section*.8}\protected@file@percent }
\newlabel{calcular-beta0}{{1.4.2}{10}{CALCULAR BETA0}{section*.9}{}}
\@writefile{toc}{\contentsline {paragraph}{CALCULAR BETA0}{10}{section*.9}\protected@file@percent }
\newlabel{recordemos-que-beta-nos-dice-cuuxe1nto-se-espera-que-cambie-y-con-un-cambio-unitario-en-las-variables-x-pero-como-hicimos-una-estandarizaciuxf3n-debe-tenerse-en-cuenta-que-este-cambio-representa-en-el-valor-estandarizado-y-no-en-el-valor-real.}{{1.4.2}{10}{Recordemos que Beta nos dice cuánto se espera que cambie Y con un cambio unitario en las variables X, pero como hicimos una estandarización, debe tenerse en cuenta que este cambio representa en el valor estandarizado y no en el valor real}{section*.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Recordemos que Beta nos dice cuánto se espera que cambie Y con un cambio unitario en las variables X, pero como hicimos una estandarización, debe tenerse en cuenta que este cambio representa en el valor estandarizado y no en el valor real.}{10}{section*.10}\protected@file@percent }
\newlabel{modelo}{{1.4.2}{10}{MODELO}{section*.11}{}}
\@writefile{toc}{\contentsline {paragraph}{MODELO}{10}{section*.11}\protected@file@percent }
\newlabel{calcular-error-cuadruxe1tico-medio-mse-la-raiz-del-error-rmse-y-el-coeficiente-de-determinaciuxf3n-ruxb2}{{1.4.2}{10}{CALCULAR ERROR CUADRÁTICO MEDIO (MSE), LA RAIZ DEL ERROR (RMSE) Y EL COEFICIENTE DE DETERMINACIÓN (R²)}{section*.12}{}}
\@writefile{toc}{\contentsline {paragraph}{CALCULAR ERROR CUADRÁTICO MEDIO (MSE), LA RAIZ DEL ERROR (RMSE) Y EL COEFICIENTE DE DETERMINACIÓN (R²)}{10}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}REPETIR EL PROCESO PARA KENDALL}{11}{subsubsection.1.4.3}\protected@file@percent }
\newlabel{repetir-el-proceso-para-kendall}{{1.4.3}{11}{REPETIR EL PROCESO PARA KENDALL}{subsubsection.1.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}REPETIR EL PROCESO PARA SPEARMAN}{11}{subsubsection.1.4.4}\protected@file@percent }
\newlabel{repetir-el-proceso-para-spearman}{{1.4.4}{11}{REPETIR EL PROCESO PARA SPEARMAN}{subsubsection.1.4.4}{}}
\newlabel{comparando-los-betas-coeficientes-de-regresiuxf3n-se-mantiene-la-direcciuxf3n-y-en-conclusiuxf3n-las-variables-que-tienen-una-fuerte-correlaciuxf3n-uxe1zucar-residual-y-alcohol-se-mantienen.-recordemos-que-el-comportamiento-no-se-puede-analizar-directamente-en-las-variables-porque-fueron-estandarizadas-inicialmente.}{{1.4.4}{12}{COMPARANDO LOS BETAS (COEFICIENTES DE REGRESIÓN), SE MANTIENE LA DIRECCIÓN Y EN CONCLUSIÓN LAS VARIABLES QUE TIENEN UNA FUERTE CORRELACIÓN (ÁZUCAR RESIDUAL Y ALCOHOL) SE MANTIENEN. RECORDEMOS QUE EL COMPORTAMIENTO NO SE PUEDE ANALIZAR DIRECTAMENTE EN LAS VARIABLES, PORQUE FUERON ESTANDARIZADAS INICIALMENTE}{section*.13}{}}
\@writefile{toc}{\contentsline {subparagraph}{COMPARANDO LOS BETAS (COEFICIENTES DE REGRESIÓN), SE MANTIENE LA DIRECCIÓN Y EN CONCLUSIÓN LAS VARIABLES QUE TIENEN UNA FUERTE CORRELACIÓN (ÁZUCAR RESIDUAL Y ALCOHOL) SE MANTIENEN. RECORDEMOS QUE EL COMPORTAMIENTO NO SE PUEDE ANALIZAR DIRECTAMENTE EN LAS VARIABLES, PORQUE FUERON ESTANDARIZADAS INICIALMENTE.}{12}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.5}AHORA ANALICEMOS LAS MEDIDAS DEL RESULTADO DE LOS MODELOS}{12}{subsubsection.1.4.5}\protected@file@percent }
\newlabel{ahora-analicemos-las-medidas-del-resultado-de-los-modelos}{{1.4.5}{12}{AHORA ANALICEMOS LAS MEDIDAS DEL RESULTADO DE LOS MODELOS}{subsubsection.1.4.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.6}El MSE: Mide el promedio de los cuadrados de los errores, es decir, la diferencia entre los valores predichos y los valores reales. Por tanto buscamos que el MSE sea bajo, indicando que el modelo tiene menor error en sus predicciones.}{12}{subsubsection.1.4.6}\protected@file@percent }
\newlabel{el-mse-mide-el-promedio-de-los-cuadrados-de-los-errores-es-decir-la-diferencia-entre-los-valores-predichos-y-los-valores-reales.-por-tanto-buscamos-que-el-mse-sea-bajo-indicando-que-el-modelo-tiene-menor-error-en-sus-predicciones.}{{1.4.6}{12}{El MSE: Mide el promedio de los cuadrados de los errores, es decir, la diferencia entre los valores predichos y los valores reales. Por tanto buscamos que el MSE sea bajo, indicando que el modelo tiene menor error en sus predicciones}{subsubsection.1.4.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.7}el RMSE es la Raíz Cuadrada del MSE, busca estar en la escala original de los datos, también se desea que sea bajo, puede ajustar mejor el valor, porque penaliza si hay errores muy grandes.}{12}{subsubsection.1.4.7}\protected@file@percent }
\newlabel{el-rmse-es-la-rauxedz-cuadrada-del-mse-busca-estar-en-la-escala-original-de-los-datos-tambiuxe9n-se-desea-que-sea-bajo-puede-ajustar-mejor-el-valor-porque-penaliza-si-hay-errores-muy-grandes.}{{1.4.7}{12}{el RMSE es la Raíz Cuadrada del MSE, busca estar en la escala original de los datos, también se desea que sea bajo, puede ajustar mejor el valor, porque penaliza si hay errores muy grandes}{subsubsection.1.4.7}{}}
\newlabel{el-menor-mse-como-el-rmse-fue-el-de-pearson-seguido-del-de-spearman-por-una-diferencia-muy-pequeuxf1a.}{{1.4.7}{12}{El menor MSE como el RMSE fue el de Pearson, seguido del de Spearman por una diferencia muy pequeña}{section*.14}{}}
\@writefile{toc}{\contentsline {paragraph}{El menor MSE como el RMSE fue el de Pearson, seguido del de Spearman por una diferencia muy pequeña.}{12}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.8}R2 (Coeficiente de determinación): Es una medida de la proporción de la varianza en la variable dependiente (Y). Un R2 más alto indica que el modelo explica una mayor proporción de la variabilidad en los datos de respuesta, finalemnte se busca tener un R2 grande.}{12}{subsubsection.1.4.8}\protected@file@percent }
\newlabel{r2-coeficiente-de-determinaciuxf3n-es-una-medida-de-la-proporciuxf3n-de-la-varianza-en-la-variable-dependiente-y.-un-r2-muxe1s-alto-indica-que-el-modelo-explica-una-mayor-proporciuxf3n-de-la-variabilidad-en-los-datos-de-respuesta-finalemnte-se-busca-tener-un-r2-grande.}{{1.4.8}{12}{R2 (Coeficiente de determinación): Es una medida de la proporción de la varianza en la variable dependiente (Y). Un R2 más alto indica que el modelo explica una mayor proporción de la variabilidad en los datos de respuesta, finalemnte se busca tener un R2 grande}{subsubsection.1.4.8}{}}
\newlabel{de-igual-manera-el-de-pearson-dio-un-r2-mayor.}{{1.4.8}{12}{De igual manera, el de Pearson dio un R2 mayor}{section*.15}{}}
\@writefile{toc}{\contentsline {paragraph}{De igual manera, el de Pearson dio un R2 mayor.}{12}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.9}Con esto se puede concluir que sí hay un buen comportamiento lineal entre los datos X vs Y, ya que Pearson es muy bueno para anlizar comportamientos lineales.}{13}{subsubsection.1.4.9}\protected@file@percent }
\newlabel{con-esto-se-puede-concluir-que-suxed-hay-un-buen-comportamiento-lineal-entre-los-datos-x-vs-y-ya-que-pearson-es-muy-bueno-para-anlizar-comportamientos-lineales.}{{1.4.9}{13}{Con esto se puede concluir que sí hay un buen comportamiento lineal entre los datos X vs Y, ya que Pearson es muy bueno para anlizar comportamientos lineales}{subsubsection.1.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}PRUEBA DE HIPÓTESIS}{13}{subsection.1.5}\protected@file@percent }
\newlabel{prueba-de-hipuxf3tesis}{{1.5}{13}{PRUEBA DE HIPÓTESIS}{subsection.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}ANALIZAR LOS RESIDUOS DEL MODELO CON PEARSON}{13}{subsubsection.1.5.1}\protected@file@percent }
\newlabel{analizar-los-residuos-del-modelo-con-pearson}{{1.5.1}{13}{ANALIZAR LOS RESIDUOS DEL MODELO CON PEARSON}{subsubsection.1.5.1}{}}
\newlabel{independencia-prueba-de-durbin-watson}{{1.5.1}{13}{INDEPENDENCIA (PRUEBA DE DURBIN WATSON)}{section*.16}{}}
\@writefile{toc}{\contentsline {paragraph}{INDEPENDENCIA (PRUEBA DE DURBIN WATSON)}{13}{section*.16}\protected@file@percent }
\newlabel{valores-del-estaduxedstico-durbin-watson-cercanos-a-2-sugieren-que-no-hay-autocorrelaciuxf3n-valores-significativamente-menores-que-2-indican-autocorrelaciuxf3n-positiva-y-valores-significativamente-mayores-que-2-indican-autocorrelaciuxf3n-negativa.-buscamos-que-no-haya-autocorrelaciuxf3n}{{1.5.1}{13}{Valores del estadístico Durbin-Watson cercanos a 2 sugieren que no hay autocorrelación, valores significativamente menores que 2 indican autocorrelación positiva, y valores significativamente mayores que 2 indican autocorrelación negativa. Buscamos que NO haya autocorrelación}{section*.17}{}}
\@writefile{toc}{\contentsline {subparagraph}{Valores del estadístico Durbin-Watson cercanos a 2 sugieren que no hay autocorrelación, valores significativamente menores que 2 indican autocorrelación positiva, y valores significativamente mayores que 2 indican autocorrelación negativa. Buscamos que NO haya autocorrelación}{13}{section*.17}\protected@file@percent }
\newlabel{normalidad-shapiro-wilks}{{1.5.1}{14}{NORMALIDAD (SHAPIRO WILKS)}{section*.18}{}}
\@writefile{toc}{\contentsline {paragraph}{NORMALIDAD (SHAPIRO WILKS)}{14}{section*.18}\protected@file@percent }
\newlabel{al-ser-un-p-value-tan-pequeuxf1o-menor-a-0.05-rechazamos-la-hiuxf3tesis-por-tanto-decimos-que-no-hay-normalidad}{{1.5.1}{14}{AL SER UN P-VALUE TAN PEQUEÑO (Menor a 0.05) RECHAZAMOS LA HIÓTESIS, POR TANTO DECIMOS QUE NO HAY NORMALIDAD}{section*.19}{}}
\@writefile{toc}{\contentsline {subparagraph}{AL SER UN P-VALUE TAN PEQUEÑO (Menor a 0.05) RECHAZAMOS LA HIÓTESIS, POR TANTO DECIMOS QUE NO HAY NORMALIDAD}{14}{section*.19}\protected@file@percent }
\newlabel{despuuxe9s-de-ver-el-gruxe1fico-efectivamente-los-puntos-no-estuxe1n-tan-encima-de-la-recta-teuxf3rica}{{1.5.1}{15}{DESPUÉS DE VER EL GRÁFICO, EFECTIVAMENTE LOS PUNTOS NO ESTÁN TAN ENCIMA DE LA RECTA TEÓRICA}{section*.20}{}}
\@writefile{toc}{\contentsline {subparagraph}{DESPUÉS DE VER EL GRÁFICO, EFECTIVAMENTE LOS PUNTOS NO ESTÁN TAN ENCIMA DE LA RECTA TEÓRICA}{15}{section*.20}\protected@file@percent }
\newlabel{media-cero-valor-esperado-de-ei-0--one-sample-t-test}{{1.5.1}{15}{MEDIA CERO (Valor Esperado de Ei = 0 -One Sample t-test)}{section*.21}{}}
\@writefile{toc}{\contentsline {paragraph}{MEDIA CERO (Valor Esperado de Ei = 0 -One Sample t-test)}{15}{section*.21}\protected@file@percent }
\newlabel{esta-vez-el-p-value-es-mayor-a-0.05-por-tanto-no-se-rechaza-la-hipuxf3tesis}{{1.5.1}{15}{ESTA VEZ EL P-VALUE ES MAYOR A 0.05 POR TANTO NO SE RECHAZA LA HIPÓTESIS}{section*.22}{}}
\@writefile{toc}{\contentsline {subparagraph}{ESTA VEZ EL P-VALUE ES MAYOR A 0.05 POR TANTO NO SE RECHAZA LA HIPÓTESIS}{15}{section*.22}\protected@file@percent }
\newlabel{homocedasticidad-varianza-constante}{{1.5.1}{17}{HOMOCEDASTICIDAD (Varianza Constante)}{section*.23}{}}
\@writefile{toc}{\contentsline {paragraph}{HOMOCEDASTICIDAD (Varianza Constante)}{17}{section*.23}\protected@file@percent }
\newlabel{el-gruxe1fico-nos-muestra-que-efectivamente-no-hay-gran-disperciuxf3n-de-los-datos-por-tanto-tienen-una-varianza-constante}{{1.5.1}{18}{EL GRÁFICO NOS MUESTRA QUE EFECTIVAMENTE NO HAY GRAN DISPERCIÓN DE LOS DATOS, POR TANTO TIENEN UNA VARIANZA CONSTANTE}{section*.24}{}}
\@writefile{toc}{\contentsline {subparagraph}{EL GRÁFICO NOS MUESTRA QUE EFECTIVAMENTE NO HAY GRAN DISPERCIÓN DE LOS DATOS, POR TANTO TIENEN UNA VARIANZA CONSTANTE}{18}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}HACERLE TRANSFORMACIÓN A LAS VARIABLES PARA AJUSTAR LA GRÁFICA LINEAL}{18}{subsection.1.6}\protected@file@percent }
\newlabel{hacerle-transformaciuxf3n-a-las-variables-para-ajustar-la-gruxe1fica-lineal}{{1.6}{18}{HACERLE TRANSFORMACIÓN A LAS VARIABLES PARA AJUSTAR LA GRÁFICA LINEAL}{subsection.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.1}Debido a la forma que presentaba la variable Cloruros frente a Densidad, podemos inferir que tiene un comportamiento Logarítmico}{18}{subsubsection.1.6.1}\protected@file@percent }
\newlabel{debido-a-la-forma-que-presentaba-la-variable-cloruros-frente-a-densidad-podemos-inferir-que-tiene-un-comportamiento-logaruxedtmico}{{1.6.1}{18}{Debido a la forma que presentaba la variable Cloruros frente a Densidad, podemos inferir que tiene un comportamiento Logarítmico}{subsubsection.1.6.1}{}}
\newlabel{hacerle-la-transformaciuxf3n-a-los-valores-originales}{{1.6.1}{19}{Hacerle la transformación a los valores originales}{section*.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Hacerle la transformación a los valores originales}{19}{section*.25}\protected@file@percent }
\newlabel{ahora-se-aplica-rauxedz-cuadrada-al-diuxf3xido-de-azuxfafre-libre-para-lograr-una-forma-muxe1s-eluxedptica-ya-que-estaba-muxe1s-cercano-a-una-cuxedrculo.-la-transformaciuxf3n-de-rauxedz-cuadrada-comprime-la-variabilidad-en-los-datos-especialmente-en-los-valores-muxe1s-altos.}{{1.6.1}{20}{Ahora se aplica raíz cuadrada al Dióxido de Azúfre Libre, para lograr una forma más elíptica, ya que estaba más cercano a una círculo. La transformación de raíz cuadrada comprime la variabilidad en los datos, especialmente en los valores más altos}{section*.26}{}}
\@writefile{toc}{\contentsline {paragraph}{Ahora se aplica raíz cuadrada al Dióxido de Azúfre Libre, para lograr una forma más elíptica, ya que estaba más cercano a una círculo. La transformación de raíz cuadrada comprime la variabilidad en los datos, especialmente en los valores más altos.}{20}{section*.26}\protected@file@percent }
\newlabel{normalizar-datos-se-haruxe1-igualmente-con-la-libreruxeda-de-sklearn-pero-con-otro-muxe9todo-de-min-y-max}{{1.6.1}{21}{Normalizar Datos, Se hará igualmente con la librería de Sklearn, pero con otro método de Min y Max}{section*.27}{}}
\@writefile{toc}{\contentsline {paragraph}{Normalizar Datos, Se hará igualmente con la librería de Sklearn, pero con otro método de Min y Max}{21}{section*.27}\protected@file@percent }
\newlabel{eliminemos-la-columna-original-de-cloruros-y-de-diuxf3xido-de-azufre}{{1.6.1}{21}{Eliminemos la columna original de Cloruros y de Dióxido de Azufre}{section*.28}{}}
\@writefile{toc}{\contentsline {paragraph}{Eliminemos la columna original de Cloruros y de Dióxido de Azufre}{21}{section*.28}\protected@file@percent }
\newlabel{revisar-las-correlaciones}{{1.6.1}{22}{REVISAR LAS CORRELACIONES}{section*.29}{}}
\@writefile{toc}{\contentsline {paragraph}{REVISAR LAS CORRELACIONES}{22}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.2}Crear un Modelo RLM con los nuevos Datos Transformados}{23}{subsubsection.1.6.2}\protected@file@percent }
\newlabel{crear-un-modelo-rlm-con-los-nuevos-datos-transformados}{{1.6.2}{23}{Crear un Modelo RLM con los nuevos Datos Transformados}{subsubsection.1.6.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.3}sm.add\_constant(): Esto añade una columna de constantes al conjunto de datos de entrada, que es necesario para que el modelo incluya un término de intercepto.}{24}{subsubsection.1.6.3}\protected@file@percent }
\newlabel{sm.add_constant-esto-auxf1ade-una-columna-de-constantes-al-conjunto-de-datos-de-entrada-que-es-necesario-para-que-el-modelo-incluya-un-tuxe9rmino-de-intercepto.}{{1.6.3}{24}{sm.add\_constant(): Esto añade una columna de constantes al conjunto de datos de entrada, que es necesario para que el modelo incluya un término de intercepto}{subsubsection.1.6.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.4}sm.RLM(): Este es el constructor para un modelo de regresión lineal robusta.}{24}{subsubsection.1.6.4}\protected@file@percent }
\newlabel{sm.rlm-este-es-el-constructor-para-un-modelo-de-regresiuxf3n-lineal-robusta.}{{1.6.4}{24}{sm.RLM(): Este es el constructor para un modelo de regresión lineal robusta}{subsubsection.1.6.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.5}El argumento M=sm.robust.norms.HuberT() especifica el tipo de estimador de robustez que se usa, en este caso usamos Huber T, que es bueno para manejar outliers.}{24}{subsubsection.1.6.5}\protected@file@percent }
\newlabel{el-argumento-msm.robust.norms.hubert-especifica-el-tipo-de-estimador-de-robustez-que-se-usa-en-este-caso-usamos-huber-t-que-es-bueno-para-manejar-outliers.}{{1.6.5}{24}{El argumento M=sm.robust.norms.HuberT() especifica el tipo de estimador de robustez que se usa, en este caso usamos Huber T, que es bueno para manejar outliers}{subsubsection.1.6.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.6}EXPLICACIÓN DE LAS ESTADÍSTICAS}{24}{subsubsection.1.6.6}\protected@file@percent }
\newlabel{explicaciuxf3n-de-las-estaduxedsticas}{{1.6.6}{24}{EXPLICACIÓN DE LAS ESTADÍSTICAS}{subsubsection.1.6.6}{}}
\newlabel{coef-coeficientes-de-regresiuxf3n}{{1.6.6}{24}{coef: Coeficientes de regresión:}{section*.30}{}}
\@writefile{toc}{\contentsline {paragraph}{coef: Coeficientes de regresión:}{24}{section*.30}\protected@file@percent }
\newlabel{representan-el-cambio-esperado-en-la-variable-dependiente-densidad-por-cada-unidad-de-cambio-en-la-variable-independiente-manteniendo-constantes-todas-las-demuxe1s-variables.}{{1.6.6}{24}{Representan el cambio esperado en la variable dependiente (Densidad) por cada unidad de cambio en la variable independiente, manteniendo constantes todas las demás variables}{section*.31}{}}
\@writefile{toc}{\contentsline {paragraph}{Representan el cambio esperado en la variable dependiente (Densidad) por cada unidad de cambio en la variable independiente, manteniendo constantes todas las demás variables.}{24}{section*.31}\protected@file@percent }
\newlabel{recordemos-que-en-este-caso-la-interpretaciuxf3n-no-puede-ser-tan-directa-ya-que-ademuxe1s-de-haberse-normalizado-tambiuxe9n-se-le-hicieron-trasnformaciones-a-2-variables-entonces-el-cambio-es-de-la-variable-transformada-y-no-de-la-original}{{1.6.6}{24}{Recordemos que en este caso la interpretación no puede ser tan directa, ya que además de haberse normalizado, también se le hicieron trasnformaciones a 2 variables, entonces el cambio es de la variable transformada y no de la original}{section*.32}{}}
\@writefile{toc}{\contentsline {paragraph}{Recordemos que en este caso la interpretación no puede ser tan directa, ya que además de haberse normalizado, también se le hicieron trasnformaciones a 2 variables, entonces el cambio es de la variable transformada y no de la original}{24}{section*.32}\protected@file@percent }
\newlabel{const-es-el-intercepto}{{1.6.6}{24}{const: Es el Intercepto}{section*.33}{}}
\@writefile{toc}{\contentsline {subparagraph}{const: Es el Intercepto}{24}{section*.33}\protected@file@percent }
\newlabel{std-err-el-error-estuxe1ndar-de-los-coeficientes-estima-la-variabilidad.-un-error-estuxe1ndar-bajo-indica-mayor-precisiuxf3n-de-la-estimaciuxf3n-del-coeficiente.}{{1.6.6}{24}{std err: El error estándar de los coeficientes estima la variabilidad. Un error estándar bajo indica mayor precisión de la estimación del coeficiente}{section*.34}{}}
\@writefile{toc}{\contentsline {paragraph}{std err: El error estándar de los coeficientes estima la variabilidad. Un error estándar bajo indica mayor precisión de la estimación del coeficiente.}{24}{section*.34}\protected@file@percent }
\newlabel{z-se-calcula-dividiendo-el-coeficiente-por-su-error-estuxe1ndar.-es-una-medida-de-cuuxe1ntas-desviaciones-estuxe1ndar-estuxe1-el-coeficiente-estimado-de-cero.}{{1.6.6}{24}{z: Se calcula dividiendo el coeficiente por su error estándar. Es una medida de cuántas desviaciones estándar está el coeficiente estimado de cero}{section*.35}{}}
\@writefile{toc}{\contentsline {paragraph}{z: Se calcula dividiendo el coeficiente por su error estándar. Es una medida de cuántas desviaciones estándar está el coeficiente estimado de cero.}{24}{section*.35}\protected@file@percent }
\newlabel{pz-valor-p-asociado-a-la-prueba-estaduxedstica-z.-se-necesita-un-valor-p-bajo-menor-a-0.05-para-rechazar-la-hipuxf3tesis-nula-no-existe-relaciuxf3n-de-que-el-coeficiente-es-igual-a-cero-indicando-que-hay-un-efecto-significativo-de-la-variable-sobre-la-respuesta.significancia-estaduxedstica}{{1.6.6}{25}{P\textgreater \textbar z\textbar : Valor p asociado a la prueba estadística z. Se necesita un valor p bajo (menor a 0.05) para rechazar la hipótesis nula (No existe relación) de que el coeficiente es igual a cero, indicando que hay un efecto significativo de la variable sobre la respuesta.(Significancia estadística)}{section*.36}{}}
\@writefile{toc}{\contentsline {paragraph}{P\textgreater \textbar z\textbar : Valor p asociado a la prueba estadística z. Se necesita un valor p bajo (menor a 0.05) para rechazar la hipótesis nula (No existe relación) de que el coeficiente es igual a cero, indicando que hay un efecto significativo de la variable sobre la respuesta.(Significancia estadística)}{25}{section*.36}\protected@file@percent }
\gdef \@abspage@last{25}
